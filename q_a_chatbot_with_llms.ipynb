{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8-PLxC1A8yvz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8-PLxC1A8yvz",
    "outputId": "8500cfa5-5148-435c-bad2-3adc7dc32f7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.11.2)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.9.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured) (2024.1.2)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.23.5)\n",
      "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured) (3.6.1)\n",
      "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured) (4.9.0)\n",
      "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured) (0.15.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured) (2023.11.17)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (1.0.0)\n",
      "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20df2b3",
   "metadata": {
    "id": "c20df2b3",
    "papermill": {
     "duration": 0.022026,
     "end_time": "2023-10-06T17:53:13.218115",
     "exception": false,
     "start_time": "2023-10-06T17:53:13.196089",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# About\n",
    "\n",
    "- Use [Langchain](https://python.langchain.com/en/latest/index.html) to build a chatbot that can answer questions about [Harry Potter books](https://www.kaggle.com/datasets/hinepo/harry-potter-books-in-pdf-1-7)\n",
    "- Experiment with various LLMs (Large Language Models)\n",
    "- Use [FAISS vector store](https://python.langchain.com/docs/integrations/vectorstores/faiss) to store text embeddings with [Sentence Transformers](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) from [Hugging Face](https://huggingface.co/hkunlp/instructor-large). FAISS runs on GPU and it is much faster than Chroma\n",
    "- Use [Retrieval chain](https://python.langchain.com/docs/modules/data_connection/retrievers/) to retrieve relevant passages from embedded text\n",
    "- Summarize retrieved passages\n",
    "- Leverage Kaggle dual GPU (2 * T4) with [Hugging Face Accelerate](https://huggingface.co/docs/accelerate/index)\n",
    "- Chat UI with [Gradio](https://www.gradio.app/guides/quickstart)\n",
    "\n",
    "No need to create any API key to use this notebook! Everything is open source.\n",
    "\n",
    "Upvote the notebook if you learn from it or use it! :)\n",
    "\n",
    "This will help me keep experimenting with new models as soon as they are released\n",
    "\n",
    "### Models\n",
    "\n",
    "- [WizardLM](https://huggingface.co/TheBloke/wizardLM-7B-HF)\n",
    "- [Falcon](https://huggingface.co/h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2)\n",
    "- [Llama 2-7b](https://huggingface.co/daryl149/llama-2-7b-chat-hf)\n",
    "- [Llama 2-13b](https://huggingface.co/daryl149/llama-2-13b-chat-hf)\n",
    "- [Bloom](https://huggingface.co/bigscience/bloom-7b1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13071e3c",
   "metadata": {
    "id": "13071e3c",
    "papermill": {
     "duration": 0.020658,
     "end_time": "2023-10-06T17:53:13.261236",
     "exception": false,
     "start_time": "2023-10-06T17:53:13.240578",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image.png](attachment:cdc462a7-e241-4332-821a-fa369a853128.png)\n",
    "\n",
    "img source: HinePo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "494c72ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T17:53:13.305662Z",
     "iopub.status.busy": "2023-10-06T17:53:13.304926Z",
     "iopub.status.idle": "2023-10-06T17:53:14.305650Z",
     "shell.execute_reply": "2023-10-06T17:53:14.304522Z"
    },
    "id": "494c72ad",
    "outputId": "ba10d706-8521-4e37-e472-02235067eabc",
    "papermill": {
     "duration": 1.026317,
     "end_time": "2023-10-06T17:53:14.307792",
     "exception": false,
     "start_time": "2023-10-06T17:53:13.281475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-c27dd88e-e1f8-8741-43c7-0b6b6516be01)\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8717746",
   "metadata": {
    "id": "e8717746",
    "papermill": {
     "duration": 0.021779,
     "end_time": "2023-10-06T17:53:14.351837",
     "exception": false,
     "start_time": "2023-10-06T17:53:14.330058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Installs\n",
    "\n",
    "This steps takes\n",
    "- ~16 s on Colab\n",
    "- ~4 min on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a8414be",
   "metadata": {
    "_kg_hide-output": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T17:53:14.396719Z",
     "iopub.status.busy": "2023-10-06T17:53:14.395630Z",
     "iopub.status.idle": "2023-10-06T17:56:59.623457Z",
     "shell.execute_reply": "2023-10-06T17:56:59.622073Z"
    },
    "id": "6a8414be",
    "outputId": "5975d8d0-cd25-459c-c6bc-f336cc2d28d8",
    "papermill": {
     "duration": 225.251594,
     "end_time": "2023-10-06T17:56:59.625560",
     "exception": false,
     "start_time": "2023-10-06T17:53:14.373966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.1.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
      "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
      "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\n",
      "torchvision 0.16.0+cu121 requires torch==2.1.0, but you have torch 2.1.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mCPU times: user 363 ms, sys: 48.7 ms, total: 412 ms\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "! pip install -qq -U langchain tiktoken pypdf faiss-gpu\n",
    "! pip install -qq -U transformers InstructorEmbedding sentence_transformers\n",
    "! pip install -qq -U accelerate bitsandbytes xformers einops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc02b2c",
   "metadata": {
    "id": "cbc02b2c",
    "papermill": {
     "duration": 0.020825,
     "end_time": "2023-10-06T17:56:59.667874",
     "exception": false,
     "start_time": "2023-10-06T17:56:59.647049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f04f73f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T17:56:59.711317Z",
     "iopub.status.busy": "2023-10-06T17:56:59.710970Z",
     "iopub.status.idle": "2023-10-06T17:57:18.165034Z",
     "shell.execute_reply": "2023-10-06T17:57:18.163680Z"
    },
    "id": "8f04f73f",
    "outputId": "b22f6f36-d905-4e0f-a0a9-22c667e4a351",
    "papermill": {
     "duration": 18.478331,
     "end_time": "2023-10-06T17:57:18.166949",
     "exception": false,
     "start_time": "2023-10-06T17:56:59.688618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain: 0.1.1\n"
     ]
    }
   ],
   "source": [
    "# Útil para suprimir mensagens que podem não ser essenciais ou relevantes para o usuário.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "# Essa linha importa o módulo glob, que fornece uma maneira de realizar correspondência de padrões em caminhos de arquivos e diretórios.\n",
    "# O glob é comumente utilizado para listar arquivos em um diretório com base em padrões de nome de arquivo que incluem curingas.\n",
    "import glob\n",
    "import textwrap\n",
    "import time\n",
    "\n",
    "import langchain\n",
    "\n",
    "# loaders\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "\n",
    "# splits\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# prompts\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# vector stores\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# models\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# retrievers\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "print('LangChain:', langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07fd989f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T17:57:18.213857Z",
     "iopub.status.busy": "2023-10-06T17:57:18.212630Z",
     "iopub.status.idle": "2023-10-06T17:57:18.227393Z",
     "shell.execute_reply": "2023-10-06T17:57:18.226269Z"
    },
    "id": "07fd989f",
    "outputId": "9e49b268-8285-4689-9a28-1da4e81e7583",
    "papermill": {
     "duration": 0.040289,
     "end_time": "2023-10-06T17:57:18.229188",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.188899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/content/data/df_100_PDF.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/content/data/*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1305bb4e",
   "metadata": {
    "id": "1305bb4e",
    "papermill": {
     "duration": 0.020878,
     "end_time": "2023-10-06T17:57:18.271847",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.250969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CFG\n",
    "\n",
    "- CFG class enables easy and organized experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5ec081f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T17:57:18.314814Z",
     "iopub.status.busy": "2023-10-06T17:57:18.314006Z",
     "iopub.status.idle": "2023-10-06T17:57:18.319411Z",
     "shell.execute_reply": "2023-10-06T17:57:18.318584Z"
    },
    "id": "c5ec081f",
    "papermill": {
     "duration": 0.028559,
     "end_time": "2023-10-06T17:57:18.321107",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.292548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # LLMs\n",
    "    model_name = 'llama2-13b' # wizardlm, bloom, falcon, llama2-7b, llama2-13b\n",
    "    temperature = 0,\n",
    "    top_p = 0.95,\n",
    "    repetition_penalty = 1.15\n",
    "\n",
    "    # splitting\n",
    "    split_chunk_size = 800\n",
    "    split_overlap = 0\n",
    "\n",
    "    # embeddings\n",
    "    embeddings_model_repo = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "\n",
    "    # similar passages\n",
    "    k = 3\n",
    "\n",
    "    # paths\n",
    "    PDFs_path = '/content/data/'\n",
    "    Embeddings_path =  '/content/faiss_index_hp'\n",
    "    Persist_directory = './celanese-vectordb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9718b906",
   "metadata": {
    "id": "9718b906",
    "papermill": {
     "duration": 0.020237,
     "end_time": "2023-10-06T17:57:18.361755",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.341518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1abccaa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T17:57:18.403666Z",
     "iopub.status.busy": "2023-10-06T17:57:18.403271Z",
     "iopub.status.idle": "2023-10-06T17:57:18.412332Z",
     "shell.execute_reply": "2023-10-06T17:57:18.411294Z"
    },
    "id": "1abccaa5",
    "papermill": {
     "duration": 0.032017,
     "end_time": "2023-10-06T17:57:18.414011",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.381994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(model = CFG.model_name):\n",
    "\n",
    "    print('\\nDownloading model: ', model, '\\n\\n')\n",
    "\n",
    "    if model == 'wizardlm':\n",
    "        model_repo = 'TheBloke/wizardLM-7B-HF'\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True\n",
    "        )\n",
    "\n",
    "        max_len = 1024\n",
    "\n",
    "    elif model == 'llama2-7b':\n",
    "        model_repo = 'daryl149/llama-2-7b-chat-hf'\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        max_len = 2048\n",
    "\n",
    "    elif model == 'llama2-13b':\n",
    "        model_repo = 'daryl149/llama-2-13b-chat-hf' # from Hugging Face\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo, use_fast=True)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "\n",
    "#             bnb_4bit_quant_type='nf4',  # Normalized float 4\n",
    "#             bnb_4bit_use_double_quant=True,  # Second quantization after the first\n",
    "#             bnb_4bit_compute_dtype=bfloat16,  # Computation type\n",
    "\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "#             low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        max_len = 8192\n",
    "\n",
    "    elif model == 'bloom':\n",
    "        model_repo = 'bigscience/bloom-7b1'\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "        )\n",
    "\n",
    "        max_len = 1024\n",
    "\n",
    "    elif model == 'falcon':\n",
    "        model_repo = 'h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2'\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_repo,\n",
    "            load_in_4bit=True,\n",
    "            device_map='auto',\n",
    "            torch_dtype=torch.float16,\n",
    "            low_cpu_mem_usage=True,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        max_len = 1024\n",
    "\n",
    "    else:\n",
    "        print(\"Not implemented model (tokenizer and backbone)\")\n",
    "\n",
    "    return tokenizer, model, max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0affd9",
   "metadata": {
    "id": "3d0affd9",
    "papermill": {
     "duration": 0.021136,
     "end_time": "2023-10-06T17:57:18.456509",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.435373",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This steps takes\n",
    "- ~3-9 min on Colab\n",
    "- ~5-8 min on kaggle, sometimes much more, up to 35 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaae7f01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "referenced_widgets": [
      "e7d17fcfa1f1442ebda9df8df3c0c682",
      "7d0c787a8237474a8013b21fa189b0a7",
      "8233a1e4487d4affa9421096d1e2ca49",
      "8f2727bb98c84108a458cb4c9a4d6d34",
      "2a576a1ec05a45a9a82a01ee36c31618",
      "574a49ae02704c9fbcc65a8195d8c6d6",
      "f9fc6b341bfe4c05a4c9decfed658c45",
      "705d260285cf45ea9dc55ee6da0a93a0",
      "5723da7154fd472a981daca917ce37f4",
      "d6e3d72f94a94ea8aea7124897e91d32",
      "e0351361c29f463c9eed0525459fb461"
     ]
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T17:57:18.501575Z",
     "iopub.status.busy": "2023-10-06T17:57:18.500754Z",
     "iopub.status.idle": "2023-10-06T18:02:42.005750Z",
     "shell.execute_reply": "2023-10-06T18:02:42.004650Z"
    },
    "id": "aaae7f01",
    "outputId": "8dcb9f0e-150b-444c-a997-37450c7c7f31",
    "papermill": {
     "duration": 323.529572,
     "end_time": "2023-10-06T18:02:42.008132",
     "exception": false,
     "start_time": "2023-10-06T17:57:18.478560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading model:  llama2-13b \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7d17fcfa1f1442ebda9df8df3c0c682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 31.2 s, total: 41.6 s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer, model, max_len = get_model(model = CFG.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c2fe01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:02:42.051867Z",
     "iopub.status.busy": "2023-10-06T18:02:42.050945Z",
     "iopub.status.idle": "2023-10-06T18:02:42.060359Z",
     "shell.execute_reply": "2023-10-06T18:02:42.059498Z"
    },
    "id": "38c2fe01",
    "outputId": "aede7b55-60a0-40a7-8921-9f803085bf49",
    "papermill": {
     "duration": 0.032843,
     "end_time": "2023-10-06T18:02:42.062031",
     "exception": false,
     "start_time": "2023-10-06T18:02:42.029188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d16b25",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:02:42.104333Z",
     "iopub.status.busy": "2023-10-06T18:02:42.104074Z",
     "iopub.status.idle": "2023-10-06T18:02:42.112934Z",
     "shell.execute_reply": "2023-10-06T18:02:42.112029Z"
    },
    "id": "03d16b25",
    "outputId": "b9ac8079-5e59-442b-fc4c-028ab45a06f3",
    "papermill": {
     "duration": 0.032346,
     "end_time": "2023-10-06T18:02:42.114687",
     "exception": false,
     "start_time": "2023-10-06T18:02:42.082341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('', 0)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### check how Accelerate split the model across the available devices (GPUs)\n",
    "model.hf_device_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4c12c5",
   "metadata": {
    "id": "1b4c12c5",
    "papermill": {
     "duration": 0.021106,
     "end_time": "2023-10-06T18:02:42.157262",
     "exception": false,
     "start_time": "2023-10-06T18:02:42.136156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🤗 pipeline\n",
    "\n",
    "- Hugging Face pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69fae65d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:02:42.201082Z",
     "iopub.status.busy": "2023-10-06T18:02:42.200753Z",
     "iopub.status.idle": "2023-10-06T18:02:42.206368Z",
     "shell.execute_reply": "2023-10-06T18:02:42.205462Z"
    },
    "id": "69fae65d",
    "papermill": {
     "duration": 0.029879,
     "end_time": "2023-10-06T18:02:42.208025",
     "exception": false,
     "start_time": "2023-10-06T18:02:42.178146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    pad_token_id = tokenizer.eos_token_id,\n",
    "    max_length = max_len,\n",
    "    temperature = CFG.temperature,\n",
    "    top_p = CFG.top_p,\n",
    "    repetition_penalty = CFG.repetition_penalty\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4431efbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:02:42.253321Z",
     "iopub.status.busy": "2023-10-06T18:02:42.252764Z",
     "iopub.status.idle": "2023-10-06T18:02:42.260438Z",
     "shell.execute_reply": "2023-10-06T18:02:42.259434Z"
    },
    "id": "4431efbd",
    "outputId": "9c8313f5-a8b4-419d-a4a3-514e1ca26bcf",
    "papermill": {
     "duration": 0.032308,
     "end_time": "2023-10-06T18:02:42.262140",
     "exception": false,
     "start_time": "2023-10-06T18:02:42.229832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7ac9833bc790>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "807309d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:02:42.307291Z",
     "iopub.status.busy": "2023-10-06T18:02:42.306688Z",
     "iopub.status.idle": "2023-10-06T18:04:00.174803Z",
     "shell.execute_reply": "2023-10-06T18:04:00.173920Z"
    },
    "id": "807309d7",
    "outputId": "43740abd-ee83-42af-af97-46ac91a6b3ae",
    "papermill": {
     "duration": 77.917346,
     "end_time": "2023-10-06T18:04:00.200764",
     "exception": false,
     "start_time": "2023-10-06T18:02:42.283418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 µs, sys: 2 µs, total: 3 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### testing model, not using the harry potter books yet\n",
    "### answer is not necessarily related to harry potter\n",
    "#query = \"Give me 5 examples of Pressure\"\n",
    "#llm(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7839f656",
   "metadata": {
    "id": "7839f656",
    "papermill": {
     "duration": 0.021585,
     "end_time": "2023-10-06T18:04:00.246497",
     "exception": false,
     "start_time": "2023-10-06T18:04:00.224912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 🦜🔗 Langchain\n",
    "\n",
    "- Multiple document retriever with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00af67c3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:04:00.307353Z",
     "iopub.status.busy": "2023-10-06T18:04:00.306779Z",
     "iopub.status.idle": "2023-10-06T18:04:00.319637Z",
     "shell.execute_reply": "2023-10-06T18:04:00.317350Z"
    },
    "id": "00af67c3",
    "outputId": "3f2c6e1d-07ff-4791-bdc5-867bd6b2b7dc",
    "papermill": {
     "duration": 0.05734,
     "end_time": "2023-10-06T18:04:00.324592",
     "exception": false,
     "start_time": "2023-10-06T18:04:00.267252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'llama2-13b'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1948ca6a",
   "metadata": {
    "id": "1948ca6a",
    "papermill": {
     "duration": 0.021101,
     "end_time": "2023-10-06T18:04:00.387203",
     "exception": false,
     "start_time": "2023-10-06T18:04:00.366102",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loader\n",
    "\n",
    "- [Directory loader](https://python.langchain.com/docs/modules/data_connection/document_loaders/file_directory) for multiple files\n",
    "- This step is not necessary if you are just loading the vector database\n",
    "- This step is necessary if you are creating embeddings. In this case you need to:\n",
    "    - load de PDF files\n",
    "    - split into chunks\n",
    "    - create embeddings\n",
    "    - save the embeddings in a vector store\n",
    "    - After that you can just load the saved embeddings to do similarity search with the user query, and then use the LLM to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i4RlDJum2K-D",
   "metadata": {
    "id": "i4RlDJum2K-D"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "x-l8YqEqBRaQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x-l8YqEqBRaQ",
    "outputId": "f90c62c5-2211-4810-ee10-297ae2a8bf2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unstructured[pdf] in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (5.2.0)\n",
      "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.4.27)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.9.4)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.8.1)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.11.2)\n",
      "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.9.0)\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2024.1.2)\n",
      "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.0.9)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.23.5)\n",
      "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.6.1)\n",
      "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (4.9.0)\n",
      "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.15.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.14.1)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.15.0)\n",
      "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (1.17.0)\n",
      "Requirement already satisfied: pdfminer.six in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (20221105)\n",
      "Requirement already satisfied: pikepdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (8.11.2)\n",
      "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (3.17.4)\n",
      "Requirement already satisfied: unstructured-inference==0.7.21 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.7.21)\n",
      "Requirement already satisfied: unstructured.pytesseract>=0.3.12 in /usr/local/lib/python3.10/dist-packages (from unstructured[pdf]) (0.3.12)\n",
      "Requirement already satisfied: layoutparser[layoutmodels,tesseract] in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[pdf]) (0.3.4)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[pdf]) (0.0.6)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[pdf]) (0.20.2)\n",
      "Requirement already satisfied: opencv-python!=4.7.0.68 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[pdf]) (4.8.0.76)\n",
      "Requirement already satisfied: onnxruntime<1.16 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[pdf]) (1.15.1)\n",
      "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-inference==0.7.21->unstructured[pdf]) (4.36.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (23.2)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured.pytesseract>=0.3.12->unstructured[pdf]) (10.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[pdf]) (2.5)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[pdf]) (0.9.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[pdf]) (4.66.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->unstructured[pdf]) (3.20.3)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six->unstructured[pdf]) (41.0.7)\n",
      "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from pikepdf->unstructured[pdf]) (1.2.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[pdf]) (2023.11.17)\n",
      "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.6)\n",
      "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[pdf]) (2.8.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (1.16.0)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[pdf]) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[pdf]) (23.5.26)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[pdf]) (1.12)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[pdf]) (3.13.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[pdf]) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[pdf]) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->unstructured-inference==0.7.21->unstructured[pdf]) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unstructured-inference==0.7.21->unstructured[pdf]) (2023.6.0)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (1.11.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (1.5.3)\n",
      "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.1.10)\n",
      "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.10.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.16.0+cu121)\n",
      "Requirement already satisfied: effdet in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.4.1)\n",
      "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.3.10)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->unstructured[pdf]) (2.21)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[pdf]) (10.0)\n",
      "Requirement already satisfied: timm>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.9.12)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.0.7)\n",
      "Requirement already satisfied: omegaconf>=2.0 in /usr/local/lib/python3.10/dist-packages (from effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.3.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (12.3.101)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2023.3.post1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (4.26.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<1.16->unstructured-inference==0.7.21->unstructured[pdf]) (1.3.0)\n",
      "Collecting torch (from layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf])\n",
      "  Using cached torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf>=2.0->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (4.9.3)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (3.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (2.1.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->effdet->layoutparser[layoutmodels,tesseract]->unstructured-inference==0.7.21->unstructured[pdf]) (3.1.1)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.2\n",
      "    Uninstalling torch-2.1.2:\n",
      "      Successfully uninstalled torch-2.1.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "xformers 0.0.23.post1 requires torch==2.1.2, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "torch",
         "torchgen"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install unstructured[pdf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "MwRvW5n32XqF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MwRvW5n32XqF",
    "outputId": "d2f2b8a5-f04c-42b4-f699-cc124047424f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 34.9 ms, total: 1.22 s\n",
      "Wall time: 1.28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    CFG.PDFs_path,\n",
    "    glob=\"./*.pdf\",\n",
    "    loader_cls=PyPDFLoader,\n",
    "    show_progress=True,\n",
    "    use_multithreading=True\n",
    ")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "780db785",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:15.937502Z",
     "iopub.status.busy": "2023-10-06T18:05:15.937228Z",
     "iopub.status.idle": "2023-10-06T18:05:15.941715Z",
     "shell.execute_reply": "2023-10-06T18:05:15.940882Z"
    },
    "id": "780db785",
    "outputId": "622403fd-4808-480c-9b3c-449e14eff486",
    "papermill": {
     "duration": 0.030473,
     "end_time": "2023-10-06T18:05:15.943540",
     "exception": false,
     "start_time": "2023-10-06T18:05:15.913067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1 pages in total\n"
     ]
    }
   ],
   "source": [
    "print(f'We have {len(documents)} pages in total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd124946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:15.989178Z",
     "iopub.status.busy": "2023-10-06T18:05:15.988924Z",
     "iopub.status.idle": "2023-10-06T18:05:15.994382Z",
     "shell.execute_reply": "2023-10-06T18:05:15.993494Z"
    },
    "id": "fd124946",
    "outputId": "f97bf482-63c8-4019-aebe-62038a3f3ba4",
    "papermill": {
     "duration": 0.030281,
     "end_time": "2023-10-06T18:05:15.996010",
     "exception": false,
     "start_time": "2023-10-06T18:05:15.965729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-48f0b798f300>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#documents[8].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8f546",
   "metadata": {
    "id": "e4d8f546",
    "papermill": {
     "duration": 0.02291,
     "end_time": "2023-10-06T18:05:16.040653",
     "exception": false,
     "start_time": "2023-10-06T18:05:16.017743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Splitter\n",
    "\n",
    "- Splitting the text into chunks so its passages are easily searchable for similarity\n",
    "- This step is also only necessary if you are creating the embeddings\n",
    "- [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/reference/modules/document_loaders.html?highlight=RecursiveCharacterTextSplitter#langchain.document_loaders.MWDumpLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da6117d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:16.084441Z",
     "iopub.status.busy": "2023-10-06T18:05:16.084140Z",
     "iopub.status.idle": "2023-10-06T18:05:16.403868Z",
     "shell.execute_reply": "2023-10-06T18:05:16.402904Z"
    },
    "id": "da6117d2",
    "outputId": "ed9e91b0-2c83-41d8-95c2-d528e7fb7fcf",
    "papermill": {
     "duration": 0.343871,
     "end_time": "2023-10-06T18:05:16.405706",
     "exception": false,
     "start_time": "2023-10-06T18:05:16.061835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have created 46 chunks from 1 pages\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = CFG.split_chunk_size,\n",
    "    chunk_overlap = CFG.split_overlap\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f'We have created {len(texts)} chunks from {len(documents)} pages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc51c2c",
   "metadata": {
    "id": "0dc51c2c",
    "papermill": {
     "duration": 0.024847,
     "end_time": "2023-10-06T18:05:16.455977",
     "exception": false,
     "start_time": "2023-10-06T18:05:16.431130",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Embeddings\n",
    "\n",
    "\n",
    "- Embedd and store the texts in a Vector database (FAISS)\n",
    "- [LangChain Vector Stores docs](https://python.langchain.com/docs/modules/data_connection/vectorstores/)\n",
    "- [FAISS - langchain](https://python.langchain.com/docs/integrations/vectorstores/faiss)\n",
    "- [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks - paper Aug/2019](https://arxiv.org/pdf/1908.10084.pdf)\n",
    "- [This is a nice 4 minutes video about vector stores](https://www.youtube.com/watch?v=dN0lsF2cvm4)\n",
    "- [Chroma - Persist and load the vector database](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/chroma.html)\n",
    "\n",
    "___\n",
    "\n",
    "- If you use Chroma vector store it will take ~35 min to create embeddings\n",
    "- If you use FAISS vector store on GPU it will take just ~3 min\n",
    "\n",
    "___\n",
    "\n",
    "We need to create the embeddings only once, and then we can just load the vector store and query the database using similarity search.\n",
    "\n",
    "Loading the embeddings takes only a few seconds.\n",
    "\n",
    "I uploaded the embeddings to a Kaggle Dataset so we just load it from [here](https://www.kaggle.com/datasets/hinepo/faiss-hp-sentence-transformers).## Create vector database\n",
    "\n",
    "- If you use Chroma vector store it will take ~35 min to create embeddings\n",
    "- If you use FAISS vector store on GPU it will take just ~3 min\n",
    "\n",
    "\n",
    "We need to create the embeddings only once, and then we can just load the vector store and query the database using similarity search.\n",
    "\n",
    "Loading the embeddings takes only a few seconds.\n",
    "\n",
    "I uploaded the embeddings to a Kaggle Dataset so we just load it from [here](https://www.kaggle.com/datasets/hinepo/faiss-hp-sentence-transformers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cd5b884",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:16.502509Z",
     "iopub.status.busy": "2023-10-06T18:05:16.502148Z",
     "iopub.status.idle": "2023-10-06T18:05:16.506688Z",
     "shell.execute_reply": "2023-10-06T18:05:16.505695Z"
    },
    "id": "2cd5b884",
    "outputId": "a3cb8739-a8d2-4d71-c581-880a8a56ca2b",
    "papermill": {
     "duration": 0.029105,
     "end_time": "2023-10-06T18:05:16.508373",
     "exception": false,
     "start_time": "2023-10-06T18:05:16.479268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# ### download embeddings model\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "     model_name = CFG.embeddings_model_repo,\n",
    "     model_kwargs = {\"device\": \"cuda\"}\n",
    " )\n",
    "\n",
    "# ### create embeddings and DB\n",
    "vectordb = FAISS.from_documents(\n",
    "     documents = texts,\n",
    "     embedding = embeddings\n",
    " )\n",
    "\n",
    "# ### persist vector database\n",
    "vectordb.save_local(\"faiss_index_hp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664a62bf",
   "metadata": {
    "id": "664a62bf",
    "papermill": {
     "duration": 0.024009,
     "end_time": "2023-10-06T18:05:16.555613",
     "exception": false,
     "start_time": "2023-10-06T18:05:16.531604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load vector database\n",
    "\n",
    "- After saving the vector database, we just load it from the Kaggle Dataset I mentioned\n",
    "- Obviously, the embeddings function to load the embeddings must be the same as the one used to create the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad7505db",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:16.601386Z",
     "iopub.status.busy": "2023-10-06T18:05:16.600548Z",
     "iopub.status.idle": "2023-10-06T18:05:22.247832Z",
     "shell.execute_reply": "2023-10-06T18:05:22.246489Z"
    },
    "id": "ad7505db",
    "outputId": "a500411a-4494-4686-f90a-ce8aab20a950",
    "papermill": {
     "duration": 5.672434,
     "end_time": "2023-10-06T18:05:22.249731",
     "exception": false,
     "start_time": "2023-10-06T18:05:16.577297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n",
      "CPU times: user 115 ms, sys: 143 ms, total: 258 ms\n",
      "Wall time: 277 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### download embeddings model\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    model_name = CFG.embeddings_model_repo,\n",
    "    model_kwargs = {\"device\": \"cuda\"}\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "g55ChcJkEDLM",
   "metadata": {
    "id": "g55ChcJkEDLM"
   },
   "outputs": [],
   "source": [
    "### load vector DB embeddings\n",
    "vectordb = FAISS.load_local(\n",
    "    CFG.Embeddings_path,\n",
    "    embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7527270d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:22.299080Z",
     "iopub.status.busy": "2023-10-06T18:05:22.298516Z",
     "iopub.status.idle": "2023-10-06T18:05:23.007935Z",
     "shell.execute_reply": "2023-10-06T18:05:23.007078Z"
    },
    "id": "7527270d",
    "outputId": "b16cd760-12e2-4428-8af9-f86bfddca8e2",
    "papermill": {
     "duration": 0.735851,
     "end_time": "2023-10-06T18:05:23.009867",
     "exception": false,
     "start_time": "2023-10-06T18:05:22.274016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Timestamp Time Day period Day of Week Month Day Month Dew Point Process Dew Point Contactor Pressure Process Contactor Pressure Natural Gas Moisture Process Natural Gas Moisture Contactor T emperature Process Contactor T emperature Glycol Moisture Process Glycol Moisture Water Inlet T emperature Process Water Inlet T emperature Glycol Inlet T emperature Process Glycol Inlet T emperature Out Glycol T emperature Process Out Glycol T emperature T emperature Process T emperature Out Water T emperature Process Out Water T emperature Stripping Gas Process Stripping Gas Pressure Process Pressure Dry Glycol Process Dry Glycol Glycol Flow Process Glycol Flow', metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content=\"31-10-2023 00:52:00 Night Tuesday 31 October -26.287443 Criticize 162.879585 Low 2.82 Normal 41.9 Low 0.86 Efficient 35.32 Normal 65.11 Normal 47.63 Good 180.739647 Keep 44.472493 Bad 84.881613 Normal 29.032323 Normal Pressure 0.22 Not Worrying 1.745114 Ok\\n18-06-2023 00:54:00 Night Sunday 18 June -14.949459 Don't Criticize 170.542602 Normal 2.32 Normal 40.4 Low 0.32 Efficient 25.65 Unwanted 59.14 Low 42.75 Good 179.472825 Not Keep 57.408797 Bad 123.608131 Normal 28.933335 Normal Pressure 0.4 Not Worrying 2.357008 Changed\\n30-12-2023 00:56:00 Night Saturday 30 December -0.329366 Don't Criticize 174.13384 Normal 3.23 Critical 49.8 High 0.38 Efficient 34.9 Normal 60.44 Normal 43.03 Good 182.058784 Keep 62.33681 Bad 120.003644 Normal 25.318454 Normal Pressure 1.85 Worrying 1.715338 Ok\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content=\"17-04-2023 01:22:00 Night Monday 17 April -9.462748 Don't Criticize 183.835195 High 3.73 Highly Critical 44.7 Normal 1.39 Inefficient 34.26 Normal 64.39 Normal 47.77 Good 177.414043 Not Keep 50.004108 Bad 104.259412 Normal 32.134558 Normal Pressure 1.81 Worrying 1.987211 Ok\\n15-12-2023 01:24:00 Night Friday 15 December -10.587682 Don't Criticize 173.619968 Normal 3.38 Critical 43.3 Low 0.62 Efficient 34.41 Normal 60.9 Normal 45.04 Good 176.276785 Not Keep 47.19467 Bad 70.256998 Normal 28.096449 Normal Pressure 0.38 Not Worrying 2.220444 Changed\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content=\"19-05-2022 03:18:00 Night Thursday 19 May -6.492189 Don't Criticize 181.395438 High 2.96 Normal 48.8 High 1.67 Inefficient 30.86 Normal 64.25 Normal 47.65 Good 183.655265 Keep 50.027672 Bad 105.156978 Normal 25.791931 Normal Pressure 0.95 Not Worrying 1.454781 Changed\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test if vector DB was loaded correctly\n",
    "vectordb.similarity_search('magic creatures')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b4de8",
   "metadata": {
    "id": "4a6b4de8",
    "papermill": {
     "duration": 0.02311,
     "end_time": "2023-10-06T18:05:23.057808",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.034698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prompt Template\n",
    "\n",
    "- Custom prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7ca8826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.104682Z",
     "iopub.status.busy": "2023-10-06T18:05:23.104389Z",
     "iopub.status.idle": "2023-10-06T18:05:23.108886Z",
     "shell.execute_reply": "2023-10-06T18:05:23.107988Z"
    },
    "id": "d7ca8826",
    "papermill": {
     "duration": 0.030048,
     "end_time": "2023-10-06T18:05:23.110588",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.080540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Timestamp Time Day period Day of Week Month Day Month\n",
    " Dew Point Process Dew Point Contactor Pressure Process\n",
    " Contactor Pressure Natural.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template = prompt_template,\n",
    "    input_variables = [\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9b39d77e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.159358Z",
     "iopub.status.busy": "2023-10-06T18:05:23.158375Z",
     "iopub.status.idle": "2023-10-06T18:05:23.162589Z",
     "shell.execute_reply": "2023-10-06T18:05:23.161763Z"
    },
    "id": "9b39d77e",
    "outputId": "2f8efb25-9d7a-476c-88da-2922b6a17f42",
    "papermill": {
     "duration": 0.029949,
     "end_time": "2023-10-06T18:05:23.164392",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.134443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template='\\nTimestamp Time Day period Day of Week Month Day Month\\n Dew Point Process Dew Point Contactor Pressure Process \\n Contactor Pressure Natural.\\n\\n{context}\\n\\nQuestion: {question}\\nAnswer:'), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7ac9833bc790>))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=PROMPT, llm=llm)\n",
    "llm_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6cba3e",
   "metadata": {
    "id": "7a6cba3e",
    "papermill": {
     "duration": 0.022321,
     "end_time": "2023-10-06T18:05:23.209557",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.187236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Retriever chain\n",
    "\n",
    "- Retriever to retrieve relevant passages\n",
    "- Chain to answer questions\n",
    "- [RetrievalQA: Chain for question-answering](https://python.langchain.com/docs/modules/data_connection/retrievers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92ebc39f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.269851Z",
     "iopub.status.busy": "2023-10-06T18:05:23.269568Z",
     "iopub.status.idle": "2023-10-06T18:05:23.274998Z",
     "shell.execute_reply": "2023-10-06T18:05:23.273976Z"
    },
    "id": "92ebc39f",
    "papermill": {
     "duration": 0.035787,
     "end_time": "2023-10-06T18:05:23.277186",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.241399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs = {\"k\": CFG.k, \"search_type\" : \"similarity\"})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\", # map_reduce, map_rerank, stuff, refine\n",
    "    retriever = retriever,\n",
    "    chain_type_kwargs = {\"prompt\": PROMPT},\n",
    "    return_source_documents = True,\n",
    "    verbose = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5e3f430",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.327003Z",
     "iopub.status.busy": "2023-10-06T18:05:23.326732Z",
     "iopub.status.idle": "2023-10-06T18:05:23.407731Z",
     "shell.execute_reply": "2023-10-06T18:05:23.406661Z"
    },
    "id": "b5e3f430",
    "outputId": "98a5e4b9-4006-4eaa-b7c9-11bf02a40e6a",
    "papermill": {
     "duration": 0.108505,
     "end_time": "2023-10-06T18:05:23.409687",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.301182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"19-05-2022 03:18:00 Night Thursday 19 May -6.492189 Don't Criticize 181.395438 High 2.96 Normal 48.8 High 1.67 Inefficient 30.86 Normal 64.25 Normal 47.65 Good 183.655265 Keep 50.027672 Bad 105.156978 Normal 25.791931 Normal Pressure 0.95 Not Worrying 1.454781 Changed\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content='Timestamp Time Day period Day of Week Month Day Month Dew Point Process Dew Point Contactor Pressure Process Contactor Pressure Natural Gas Moisture Process Natural Gas Moisture Contactor T emperature Process Contactor T emperature Glycol Moisture Process Glycol Moisture Water Inlet T emperature Process Water Inlet T emperature Glycol Inlet T emperature Process Glycol Inlet T emperature Out Glycol T emperature Process Out Glycol T emperature T emperature Process T emperature Out Water T emperature Process Out Water T emperature Stripping Gas Process Stripping Gas Pressure Process Pressure Dry Glycol Process Dry Glycol Glycol Flow Process Glycol Flow', metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content=\"05-02-2022 01:38:00 Night Saturday 5 February -16.32265 Don't Criticize 171.803727 Normal 1.57 Normal 48.6 High 1.82 Inefficient 41.67 Problem 61.59 Normal 49.15 Good 177.734017 Not Keep 49.512581 Bad 107.642442 Normal 28.650829 Normal Pressure 1.89 Worrying 2.338875 Changed\\n22-05-2023 01:40:00 Night Monday 22 May -15.355248 Don't Criticize 174.859717 Normal 3.74 Highly Critical 44.0 Low 0.39 Efficient 30.2 Normal 58.64 Low 46.14 Good 176.451637 Not Keep 62.02316 Bad 149.033286 Normal 30.012477 Normal Pressure 0.73 Not Worrying 2.337234 Changed\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing MMR search\n",
    "question = \"how to use Dew point on 01-09-2023?\"\n",
    "vectordb.max_marginal_relevance_search(question, k = CFG.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e31f23b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.466185Z",
     "iopub.status.busy": "2023-10-06T18:05:23.465410Z",
     "iopub.status.idle": "2023-10-06T18:05:23.487009Z",
     "shell.execute_reply": "2023-10-06T18:05:23.486064Z"
    },
    "id": "2e31f23b",
    "outputId": "6cec8662-e6ae-403f-9323-7d85a6eec791",
    "papermill": {
     "duration": 0.04983,
     "end_time": "2023-10-06T18:05:23.488720",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.438890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"19-05-2022 03:18:00 Night Thursday 19 May -6.492189 Don't Criticize 181.395438 High 2.96 Normal 48.8 High 1.67 Inefficient 30.86 Normal 64.25 Normal 47.65 Good 183.655265 Keep 50.027672 Bad 105.156978 Normal 25.791931 Normal Pressure 0.95 Not Worrying 1.454781 Changed\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content='Timestamp Time Day period Day of Week Month Day Month Dew Point Process Dew Point Contactor Pressure Process Contactor Pressure Natural Gas Moisture Process Natural Gas Moisture Contactor T emperature Process Contactor T emperature Glycol Moisture Process Glycol Moisture Water Inlet T emperature Process Water Inlet T emperature Glycol Inlet T emperature Process Glycol Inlet T emperature Out Glycol T emperature Process Out Glycol T emperature T emperature Process T emperature Out Water T emperature Process Out Water T emperature Stripping Gas Process Stripping Gas Pressure Process Pressure Dry Glycol Process Dry Glycol Glycol Flow Process Glycol Flow', metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0}),\n",
       " Document(page_content=\"17-04-2023 01:22:00 Night Monday 17 April -9.462748 Don't Criticize 183.835195 High 3.73 Highly Critical 44.7 Normal 1.39 Inefficient 34.26 Normal 64.39 Normal 47.77 Good 177.414043 Not Keep 50.004108 Bad 104.259412 Normal 32.134558 Normal Pressure 1.81 Worrying 1.987211 Ok\\n15-12-2023 01:24:00 Night Friday 15 December -10.587682 Don't Criticize 173.619968 Normal 3.38 Critical 43.3 Low 0.62 Efficient 34.41 Normal 60.9 Normal 45.04 Good 176.276785 Not Keep 47.19467 Bad 70.256998 Normal 28.096449 Normal Pressure 0.38 Not Worrying 2.220444 Changed\", metadata={'source': '/content/data/df_100_PDF.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing similarity search\n",
    "question = \"how to use Dew point on 01-09-2023?\"\n",
    "vectordb.similarity_search(question, k = CFG.k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b63a44",
   "metadata": {
    "id": "66b63a44",
    "papermill": {
     "duration": 0.023655,
     "end_time": "2023-10-06T18:05:23.535454",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.511799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Post-process outputs\n",
    "\n",
    "- Format llm response\n",
    "- Cite sources (PDFs)\n",
    "- Change `width` parameter to format the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45cc3ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.584594Z",
     "iopub.status.busy": "2023-10-06T18:05:23.583957Z",
     "iopub.status.idle": "2023-10-06T18:05:23.590868Z",
     "shell.execute_reply": "2023-10-06T18:05:23.589917Z"
    },
    "id": "45cc3ac6",
    "papermill": {
     "duration": 0.034174,
     "end_time": "2023-10-06T18:05:23.592983",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.558809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wrap_text_preserve_newlines(text, width=700):\n",
    "    # Split the input text into lines based on newline characters\n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Wrap each line individually\n",
    "    wrapped_lines = [textwrap.fill(line, width=width) for line in lines]\n",
    "\n",
    "    # Join the wrapped lines back together using newline characters\n",
    "    wrapped_text = '\\n'.join(wrapped_lines)\n",
    "\n",
    "    return wrapped_text\n",
    "\n",
    "\n",
    "def process_llm_response(llm_response):\n",
    "    ans = wrap_text_preserve_newlines(llm_response['result'])\n",
    "\n",
    "    sources_used = ' \\n'.join(\n",
    "        [\n",
    "            source.metadata['source'].split('/')[-1][:-4] + ' - page: ' + str(source.metadata['page'])\n",
    "            for source in llm_response['source_documents']\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ans = ans + '\\n\\nSources: \\n' + sources_used\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9292c110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.641860Z",
     "iopub.status.busy": "2023-10-06T18:05:23.641260Z",
     "iopub.status.idle": "2023-10-06T18:05:23.646519Z",
     "shell.execute_reply": "2023-10-06T18:05:23.645714Z"
    },
    "id": "9292c110",
    "papermill": {
     "duration": 0.031264,
     "end_time": "2023-10-06T18:05:23.648155",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.616891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_ans(query):\n",
    "    start = time.time()\n",
    "    llm_response = qa_chain(query)\n",
    "    ans = process_llm_response(llm_response)\n",
    "    end = time.time()\n",
    "\n",
    "    time_elapsed = int(round(end - start, 0))\n",
    "    time_elapsed_str = f'\\n\\nTime elapsed: {time_elapsed} s'\n",
    "    return ans + time_elapsed_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200bc08",
   "metadata": {
    "id": "8200bc08",
    "papermill": {
     "duration": 0.023552,
     "end_time": "2023-10-06T18:05:23.694747",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.671195",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Ask questions\n",
    "\n",
    "- Question Answering from multiple documents\n",
    "- Run QA Chain\n",
    "- Talk to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f6145f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.745085Z",
     "iopub.status.busy": "2023-10-06T18:05:23.744825Z",
     "iopub.status.idle": "2023-10-06T18:05:23.750085Z",
     "shell.execute_reply": "2023-10-06T18:05:23.749259Z"
    },
    "id": "5f6145f4",
    "outputId": "a32e2d17-069d-402c-cbc2-a647c4356a50",
    "papermill": {
     "duration": 0.033251,
     "end_time": "2023-10-06T18:05:23.751810",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.718559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'llama2-13b'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7299d189",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.800571Z",
     "iopub.status.busy": "2023-10-06T18:05:23.799848Z",
     "iopub.status.idle": "2023-10-06T18:05:23.807902Z",
     "shell.execute_reply": "2023-10-06T18:05:23.806970Z"
    },
    "id": "7299d189",
    "outputId": "1e84b2d6-8d53-4f5a-ded5-464f457eefa8",
    "papermill": {
     "duration": 0.034385,
     "end_time": "2023-10-06T18:05:23.809609",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.775224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 5120, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-39): 40 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (k_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (v_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (o_proj): Linear4bit(in_features=5120, out_features=5120, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=5120, out_features=13824, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=13824, out_features=5120, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=5120, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c695d9cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:23.859908Z",
     "iopub.status.busy": "2023-10-06T18:05:23.859264Z",
     "iopub.status.idle": "2023-10-06T18:05:31.692373Z",
     "shell.execute_reply": "2023-10-06T18:05:31.691386Z"
    },
    "id": "c695d9cb",
    "outputId": "f58a3335-1a42-411c-8199-a3637d52c48b",
    "papermill": {
     "duration": 7.860812,
     "end_time": "2023-10-06T18:05:31.694141",
     "exception": false,
     "start_time": "2023-10-06T18:05:23.833329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the data provided, the dew point on 01-09-2023 was -9.462748 degrees Celsius. To determine if it is safe to use the system, you would need to consult the manufacturer's guidelines for the specific system and the ambient conditions on that day. However, based on the data provided, the temperature was below freezing and the humidity was low, which may indicate that the system was not operating efficiently or effectively. It is important to consider all relevant factors before making any decisions about using the system.\n",
      "\n",
      "Sources: \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0\n",
      "\n",
      "Time elapsed: 28 s\n"
     ]
    }
   ],
   "source": [
    "query = \"how to use Dew point on 01-09-2023?\"\n",
    "print(llm_ans(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2f10b233",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:31.747243Z",
     "iopub.status.busy": "2023-10-06T18:05:31.746832Z",
     "iopub.status.idle": "2023-10-06T18:05:55.177275Z",
     "shell.execute_reply": "2023-10-06T18:05:55.175886Z"
    },
    "id": "2f10b233",
    "outputId": "84764f86-f0fc-41c5-fbd3-0c873e526026",
    "papermill": {
     "duration": 23.459003,
     "end_time": "2023-10-06T18:05:55.179301",
     "exception": false,
     "start_time": "2023-10-06T18:05:31.720298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here is the information about Dew Point on 01-09-2023 based on the data provided:\n",
      "\n",
      "Dew Point (°C): 10.587682\n",
      "\n",
      "Note that this value is for the specific date and time of 01-09-2023 at 01:24:00, and may not be representative of other times or dates.\n",
      "\n",
      "Sources: \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0\n",
      "\n",
      "Time elapsed: 21 s\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me the information about Dew Point in 01-09-2023?\"\n",
    "print(llm_ans(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a6fc5e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:05:55.229908Z",
     "iopub.status.busy": "2023-10-06T18:05:55.229602Z",
     "iopub.status.idle": "2023-10-06T18:06:00.669096Z",
     "shell.execute_reply": "2023-10-06T18:06:00.667933Z"
    },
    "id": "4a6fc5e9",
    "outputId": "1d42c4b4-0158-43cd-f3aa-e177fa2c5e0e",
    "papermill": {
     "duration": 5.466316,
     "end_time": "2023-10-06T18:06:00.671024",
     "exception": false,
     "start_time": "2023-10-06T18:05:55.204708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here is the information about Glycol Moisture on 01-09-2023 based on the data provided:\n",
      "\n",
      "Glycol Moisture (%): 34.26\n",
      "\n",
      "Note that this value is normal, and there is no critical or highly critical condition detected.\n",
      "\n",
      "Sources: \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0\n",
      "\n",
      "Time elapsed: 17 s\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me the information about Glycol Moisture in 01-09-2023?\"\n",
    "print(llm_ans(query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "86a8571c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:06:00.724936Z",
     "iopub.status.busy": "2023-10-06T18:06:00.724628Z",
     "iopub.status.idle": "2023-10-06T18:06:24.124033Z",
     "shell.execute_reply": "2023-10-06T18:06:24.123036Z"
    },
    "id": "86a8571c",
    "outputId": "2098cae9-7632-482b-bb90-167815efd74d",
    "papermill": {
     "duration": 23.428634,
     "end_time": "2023-10-06T18:06:24.126031",
     "exception": false,
     "start_time": "2023-10-06T18:06:00.697397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure! Here are five examples of df_100_PDF, each with a different timestamp and set of values:\n",
      "\n",
      "Example 1 (timestamp: 17-04-2023 01:22:00)\n",
      "df_100_PDF = [183.835195, 3.73, 'High', 44.7, 'Normal', 1.39, 'Inefficient', 34.26, 'Normal', 64.39, 'Good']\n",
      "\n",
      "Example 2 (timestamp: 15-12-2023 01:24:00)\n",
      "df_100_PDF = [173.619968, 3.38, 'Critical', 43.3, 'Low', 0.62, 'Efficient', 34.41, 'Normal', 60.9, 'Good']\n",
      "\n",
      "Example 3 (timestamp: 10-10-2023 02:56:00)\n",
      "df_100_PDF = [161.333793, 3.51, 'Highly Critical', 47.0, 'High', 1.33, 'Inefficient', 37.42, 'Normal', 70.73, 'Good']\n",
      "\n",
      "Example 4 (timestamp: 11-11-2022 02:58:00)\n",
      "df_100_PDF = [180.076508, 3.29, 'Critical', 49.5, 'High', 0.47, 'Efficient', 41.82, 'Problem', 69.66, 'Normal']\n",
      "\n",
      "Example 5 (timestamp: 01-01-2023 00:00:00)\n",
      "df_100_PDF = [100.0, 0.0, 'Not Applicable', 0.0, 'Not Applicable', 0.0, 'Not Applicable', 0.0, 'Not Applicable', 0.0, 'Not Applicable']\n",
      "\n",
      "Sources: \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0 \n",
      "df_100_PDF - page: 0\n",
      "\n",
      "Time elapsed: 94 s\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me 5 examples of df_100_PDF\"\n",
    "print(llm_ans(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae013fc",
   "metadata": {
    "id": "7ae013fc",
    "papermill": {
     "duration": 0.023931,
     "end_time": "2023-10-06T18:06:24.175108",
     "exception": false,
     "start_time": "2023-10-06T18:06:24.151177",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gradio Chat UI\n",
    "\n",
    "- Create a chat UI with [Gradio](https://www.gradio.app/guides/quickstart)\n",
    "- [ChatInterface docs](https://www.gradio.app/docs/chatinterface)\n",
    "- The notebook should be running if you want to use the chat interface\n",
    "- Print of the chat UI below\n",
    "- **Gradio has better compatibility with Colab than with Kaggle. If you plan to use the interface, it is preferable to do so in Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2fd25a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:06:24.226661Z",
     "iopub.status.busy": "2023-10-06T18:06:24.226032Z",
     "iopub.status.idle": "2023-10-06T18:06:24.231021Z",
     "shell.execute_reply": "2023-10-06T18:06:24.230150Z"
    },
    "id": "2fd25a70",
    "papermill": {
     "duration": 0.033298,
     "end_time": "2023-10-06T18:06:24.232672",
     "exception": false,
     "start_time": "2023-10-06T18:06:24.199374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### necessary for google colab\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c8843bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-06T18:06:24.280540Z",
     "iopub.status.busy": "2023-10-06T18:06:24.279926Z",
     "iopub.status.idle": "2023-10-06T18:06:39.779950Z",
     "shell.execute_reply": "2023-10-06T18:06:39.778610Z"
    },
    "id": "6c8843bd",
    "papermill": {
     "duration": 15.526643,
     "end_time": "2023-10-06T18:06:39.782303",
     "exception": false,
     "start_time": "2023-10-06T18:06:24.255660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade gradio -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "HP3A1TcBS3cI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HP3A1TcBS3cI",
    "outputId": "018b0738-00ab-4f8a-e92f-0fb1322efedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.109.0)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.1)\n",
      "Requirement already satisfied: gradio-client==0.8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.0)\n",
      "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.5.3)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.6)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (2023.6.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.14.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
      "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.0)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.35.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.7.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.0.2)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.32.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac10bb0d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:06:39.834972Z",
     "iopub.status.busy": "2023-10-06T18:06:39.834640Z",
     "iopub.status.idle": "2023-10-06T18:06:40.997100Z",
     "shell.execute_reply": "2023-10-06T18:06:40.995699Z"
    },
    "id": "ac10bb0d",
    "outputId": "3cf98b70-8562-4a07-fd86-6189c66c12fc",
    "papermill": {
     "duration": 1.190888,
     "end_time": "2023-10-06T18:06:40.999021",
     "exception": false,
     "start_time": "2023-10-06T18:06:39.808133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.14.0\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "print(gr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4e82caaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "execution": {
     "iopub.execute_input": "2023-10-06T18:06:41.050536Z",
     "iopub.status.busy": "2023-10-06T18:06:41.049713Z",
     "iopub.status.idle": "2023-10-06T18:06:47.394502Z",
     "shell.execute_reply": "2023-10-06T18:06:47.393245Z"
    },
    "id": "4e82caaa",
    "outputId": "83708618-0c41-4ab0-b851-b1296addfc8a",
    "papermill": {
     "duration": 6.371613,
     "end_time": "2023-10-06T18:06:47.396422",
     "exception": false,
     "start_time": "2023-10-06T18:06:41.024809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://a077dfa60d60500dec.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://a077dfa60d60500dec.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(message, history):\n",
    "    # output = message # debug mode\n",
    "\n",
    "    output = str(llm_ans(message)).replace(\"\\n\", \"<br/>\")\n",
    "    return output\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    predict,\n",
    "    title = f' Open-Source LLM ({CFG.model_name}) for Celanese Question Answering'\n",
    ")\n",
    "\n",
    "demo.queue()\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2b0ba",
   "metadata": {
    "id": "b7e2b0ba",
    "papermill": {
     "duration": 0.029099,
     "end_time": "2023-10-06T18:06:47.451522",
     "exception": false,
     "start_time": "2023-10-06T18:06:47.422423",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image.png](attachment:413fe7a3-6534-45b5-b6e3-7fc86e982cf1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d250f7c8",
   "metadata": {
    "id": "d250f7c8",
    "papermill": {
     "duration": 0.023887,
     "end_time": "2023-10-06T18:06:47.507306",
     "exception": false,
     "start_time": "2023-10-06T18:06:47.483419",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image.png](attachment:976f4bf4-7626-4d4a-b773-3eebd7e9f000.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f164d2",
   "metadata": {
    "id": "56f164d2",
    "papermill": {
     "duration": 0.024714,
     "end_time": "2023-10-06T18:06:47.557091",
     "exception": false,
     "start_time": "2023-10-06T18:06:47.532377",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Conclusions\n",
    "\n",
    "- Feel free to fork and optimize the code. Lots of things can be improved.\n",
    "\n",
    "- Things I found had the most impact on models output quality in my experiments:\n",
    "    - Prompt engineering\n",
    "    - Bigger models\n",
    "    - Other models families\n",
    "    - Splitting: chunk size, overlap\n",
    "    - Search: Similarity, MMR, k\n",
    "    - Pipeline parameters (temperature, top_p, penalty)\n",
    "    - Embeddings function\n",
    "    - LLM parameters (max len)\n",
    "\n",
    "\n",
    "- LangChain, Hugging Face and Gradio are awesome libs!\n",
    "\n",
    "- Upvote if you liked it or want me to keep updating this with new models and functionalities!\n",
    "\n",
    "🦜🔗🤗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc5126",
   "metadata": {
    "id": "e0dc5126",
    "papermill": {
     "duration": 0.024525,
     "end_time": "2023-10-06T18:06:47.605070",
     "exception": false,
     "start_time": "2023-10-06T18:06:47.580545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "![image.png](attachment:68773819-4358-4ded-be3e-f1d275103171.png)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 827.003053,
   "end_time": "2023-10-06T18:06:50.862060",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-06T17:53:03.859007",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2a576a1ec05a45a9a82a01ee36c31618": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5723da7154fd472a981daca917ce37f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "574a49ae02704c9fbcc65a8195d8c6d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "705d260285cf45ea9dc55ee6da0a93a0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d0c787a8237474a8013b21fa189b0a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_574a49ae02704c9fbcc65a8195d8c6d6",
      "placeholder": "​",
      "style": "IPY_MODEL_f9fc6b341bfe4c05a4c9decfed658c45",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "8233a1e4487d4affa9421096d1e2ca49": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_705d260285cf45ea9dc55ee6da0a93a0",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5723da7154fd472a981daca917ce37f4",
      "value": 3
     }
    },
    "8f2727bb98c84108a458cb4c9a4d6d34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6e3d72f94a94ea8aea7124897e91d32",
      "placeholder": "​",
      "style": "IPY_MODEL_e0351361c29f463c9eed0525459fb461",
      "value": " 3/3 [02:16&lt;00:00, 42.80s/it]"
     }
    },
    "d6e3d72f94a94ea8aea7124897e91d32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0351361c29f463c9eed0525459fb461": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e7d17fcfa1f1442ebda9df8df3c0c682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d0c787a8237474a8013b21fa189b0a7",
       "IPY_MODEL_8233a1e4487d4affa9421096d1e2ca49",
       "IPY_MODEL_8f2727bb98c84108a458cb4c9a4d6d34"
      ],
      "layout": "IPY_MODEL_2a576a1ec05a45a9a82a01ee36c31618"
     }
    },
    "f9fc6b341bfe4c05a4c9decfed658c45": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
